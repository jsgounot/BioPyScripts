import glob, os

# Read this
# https://github.com/jsgounot/metagenomic-pipelines/wiki/Reads-compression
# NOTE : This script might use a lot of disk space during runtime (multiple file copies for check purpose)
# This could be improved by adding a conditionnal rule during the checking analysis
# but this is not something easily done with snakemake
# Look Spring option for long reads !

fnames = "input/*.fastq.gz"
fnames = sorted(glob.glob(fnames))
fnames = {os.path.basename(fname)[:-9] : fname for fname in fnames}

rule all:
    input:
        expand("output/{name}.spring", name=list(fnames)),
        expand("output/{name}.cmp", name=list(fnames)),
        "output/compression.stat.tsv"

rule compress:
    input:
        lambda wc : fnames[wc.name]
    output:
        "output/{name}.spring"
    threads:
        8
    group:
        "main"
    shell:
        "spring -c -g -t {threads} -i {input} -o {output}"

rule uncompress:
    input:
        "output/{name}.spring"
    output:
        "check/{name}.fastq.gz"
    threads:
        8
    group:
        "main"
    shell:
        "spring -d -g -t {threads} -i {input} -o {output}"

checkpoint raw_cmp:
    input:
        f1 = "check/{name}.fastq.gz",
        f2 = lambda wc : fnames[wc.name]
    output:
        "output/{name}.raw.cmp"
    shell:
        # We need to add `|| true` at the end since zcmp return exit 
        # code 1 if diff is found which make snakemake stop
        "zcmp {input.f1} {input.f2} > {output} || true"

# ------------------------------------------------------------------------
# Case 1: Fastq gz files are directly the same
# This rule is used to clean fastq file
# Since temp() does not work well with checkpoint rules

rule clean_raw_cmp:
    input:
        cmpf = "output/{name}.raw.cmp",
        fqz  = "check/{name}.fastq.gz"
    output:
        "output/{name}.raw.clean.cmp"
    shell:
        "mv {input.cmpf} {output} && rm {input.fqz}"

# ------------------------------------------------------------------------
# Case 2: Fastq gz files are NOT directly the same
# Might be due to optional line 3 differences
# Need to awk both fastq.gz and zcmp again

rule awk_uncompress_spring:
    input:
        "check/{name}.fastq.gz"
    output:
        temp("check/{name}.spring.awked.gz")
    shell:
        "awk '(NR%4!=3)' <(gzip -dc {input}) | gzip > {output} && rm {input}"

rule awk_uncompress_original:
    input:
        lambda wc : fnames[wc.name]
    output:
        temp("check/{name}.original.awked.gz")
    shell:
        "awk '(NR%4!=3)' <(gzip -dc {input}) | gzip > {output}"

rule check_cmp:
    input:
        f1 = "check/{name}.spring.awked.gz",
        f2 = "check/{name}.original.awked.gz",
        f3 = "output/{name}.raw.cmp"
    output:
        "output/{name}.awk.cmp"
    shell:
        "zcmp {input.f1} {input.f2} > {output} && rm {input.f3}"

# ------------------------------------------------------------------------
# Aggregation to check if we need to go through case #2 

def aggregate_cmp(wildcards):
    # input function for the rule aggregate
    # https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html#data-dependent-conditional-execution
    # in this context we want to run the awk cmp only if gcmp is not good
    # which can happen if the optional identifier vary between the uncompressed and default read files

    with checkpoints.raw_cmp.get(name=wildcards.name).output[0].open() as f:
        if f.read().strip() != "":
            return "output/{name}.awk.cmp"
        else:
            return "output/{name}.raw.clean.cmp"

rule mv_cmp:
    input:
        aggregate_cmp
    output:
        "output/{name}.cmp"
    shell:
        "mv {input} {output}"

rule make_table:
    input:
        expand("output/{name}.spring", name=list(fnames))
    output:
        "output/compression.stat.tsv"
    script:
        "compression.stat.py"